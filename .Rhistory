head(spotify)
# We are interested in the relationship between popularity of a song multiple covariates #
#Name: Julian Griffin
#Function: Linear Regression of Spotify Data Set to find relationships between data
#Set working directory and assign a variable name to the dataset
setwd("/Users/juliangriffin/Desktop/R_Projects_Local/R_Projects")
spotify <- read.csv("spotify.csv")
# We are interested in the relationship between popularity of a song multiple covariates #
#Name: Julian Griffin
#Function: Linear Regression of Spotify Data Set to find relationships between data
#Set working directory and assign a variable name to the dataset
setwd("/Users/juliangriffin/Desktop/R_Projects_Local/R_Projects")
spotify <- read.csv("spotify_data.csv")
head(spotify)
# We are interested in the relationship between popularity of a song multiple covariates #
#Name: Julian Griffin
#Function: Linear Regression of Spotify Data Set to find relationships between data
#Set working directory and assign a variable name to the dataset
setwd("/Users/juliangriffin/Desktop/R_Projects_Local/R_Projects")
spotify <- read.csv("spotify_data.csv")
#Check if data loaded in properly
head(spotify)
#Run Multiple Linear Regression on the dataset
model -> lm(popularity ~ duration_ms + danceability + energy + acousticness + instrumentalness + liveness + tempo, data = spotify)
summary(model)
MLR -> lm(popularity ~ duration_ms + danceability + energy + acousticness + instrumentalness + liveness + tempo, data = spotify)
summary(MLR)
# We are interested in the relationship between popularity of a song multiple covariates #
#Name: Julian Griffin
#Function: Linear Regression of Spotify Data Set to find relationships between data
#Set working directory and assign a variable name to the dataset
setwd("/Users/juliangriffin/Desktop/R_Projects_Local/R_Projects")
spotify <- read.csv("spotify_data.csv")
#Check if data loaded in properly
head(spotify)
#Run Multiple Linear Regression on the dataset
model -> lm(popularity ~ duration_ms + danceability + energy + acousticness + instrumentalness + liveness + tempo, data = spotify)
# We are interested in the relationship between popularity of a song multiple covariates #
#Name: Julian Griffin
#Function: Linear Regression of Spotify Data Set to find relationships between data
#Set working directory and assign a variable name to the dataset
setwd("/Users/juliangriffin/Desktop/R_Projects_Local/R_Projects")
spotify <- read.csv("spotify_data.csv")
#Check if data loaded in properly
head(spotify)
#Run Multiple Linear Regression on the dataset
model <- lm(popularity ~ duration_ms + danceability + energy + acousticness + instrumentalness + liveness + tempo, data = spotify)
summary(model)
new_model <- lm(popularity ~ duration_ms + danceability + energy + instrumentalness + liveness + tempo, data = spotify)
summary(new_model)
new_model <- lm(popularity ~ duration_ms + danceability + acousticness + instrumentalness + liveness + tempo, data = spotify)
summary(new_model)
# We are interested in the relationship between popularity of a song multiple covariates #
#Name: Julian Griffin
#Function: Linear Regression of Spotify Data Set to find relationships between data
#Set working directory and assign a variable name to the dataset
setwd("/Users/juliangriffin/Desktop/R_Projects_Local/R_Projects")
spotify <- read.csv("spotify_data.csv")
#Check if data loaded in properly
head(spotify)
#Run Multiple Linear Regression on the dataset
model <- lm(popularity ~ duration_ms + danceability + energy + acousticness + instrumentalness + liveness + tempo, data = spotify)
summary(model)
# Key Findings
# 1. Model Fit:
#       What - Our model only explains about 1% of the total variation of the data (very low)
#       How - R^2 = 0.01 (which ranges from 0-1)
# 2. Most Influential Factors:
#       What - Danceability increases popularity while energy, acousticness, and instrumentalness negatively affect popularity
#       How - The estimate coefficients are positive/negative respectively
# Next steps:
# We should look to check for violations of assumptions and analyze the data with outliers removed
new_model <- lm(popularity ~ duration_ms + danceability + energy + instrumentalness + liveness + tempo, data = spotify)
summary(new_model)
# -----------------------------------------------------------------------------------------------------------------------------------------
# Spotify Song Popularity Analysis: Linear Regression
# -----------------------------------------------------------------------------------------------------------------------------------------
# Author: Julian Griffin
# Purpose: Investigate the relationship between song popularity and multiple characteristics using linear regression
# Data Set: Kelly Ramsay
# -----------------------------------------------------------------------------------------------------------------------------------------
# Set working directory and import the dataset
setwd("/Users/juliangriffin/Desktop/R_Projects_Local/R_Projects")
spotify <- read.csv("spotify_data.csv")
# Check if data loaded in properly
head(spotify)
# -----------------------------------------------------------------------------------------------------------------------------------------
# Step 1: Fit the Full Multiple Linear Regression Model
# -----------------------------------------------------------------------------------------------------------------------------------------
model_full <- lm(popularity ~ duration_ms + danceability + energy + acousticness + instrumentalness + liveness + tempo, data = spotify)
summary(model_full)
# -----------------------------------------------------------------------------------------------------------------------------------------
# Key Findings from Step 1 (Full Model):
# -----------------------------------------------------------------------------------------------------------------------------------------
# 1. Model Fit:
#      - Our model explains only ~1% of the variability in popularity (R^2 = 0.01139).
#      - Adjusted R^2 confirms a similarly low explanatory power.
# 2. Influential Factors:
#      - Danceability positively impacts popularity.
#      - Energy, acousticness, and instrumentalness negatively impact popularity.
# 3. Non-Significant Predictors:
#      - Liveness and duration_ms show no significant impact.
# -----------------------------------------------------------------------------------------------------------------------------------------
# Step 2: Check for Multicollinearity
# -----------------------------------------------------------------------------------------------------------------------------------------
# Install the 'car' package if not already installed
if (!require(car)) install.packages("car")
library(car)
# Calculate Variance Inflation Factor (VIF) for predictors
vif_values <- vif(model_full)
print(vif_values)
# -----------------------------------------------------------------------------------------------------------------------------------------
# Spotify Song Popularity Analysis: Linear Regression
# -----------------------------------------------------------------------------------------------------------------------------------------
# Author: Julian Griffin
# Purpose: Investigate the relationship between song popularity and multiple characteristics using linear regression
# Data Set: Kelly Ramsay
# -----------------------------------------------------------------------------------------------------------------------------------------
# Set working directory and import the dataset
setwd("/Users/juliangriffin/Desktop/R_Projects_Local/R_Projects")
spotify <- read.csv("spotify_data.csv")
# Check if data loaded in properly
head(spotify)
# -----------------------------------------------------------------------------------------------------------------------------------------
# Step 1: Fit the Full Multiple Linear Regression Model
# -----------------------------------------------------------------------------------------------------------------------------------------
model_full <- lm(popularity ~ duration_ms + danceability + energy + acousticness + instrumentalness + liveness + tempo, data = spotify)
summary(model_full)
# -----------------------------------------------------------------------------------------------------------------------------------------
# Key Findings from Step 1 (Full Model):
# -----------------------------------------------------------------------------------------------------------------------------------------
# 1. Model Fit:
#      - Our model explains only ~1% of the variability in popularity (R^2 = 0.01139).
#      - Adjusted R^2 confirms a similarly low explanatory power.
# 2. Influential Factors:
#      - Danceability positively impacts popularity.
#      - Energy, acousticness, and instrumentalness negatively impact popularity.
# 3. Non-Significant Predictors:
#      - Liveness and duration_ms show no significant impact.
# -----------------------------------------------------------------------------------------------------------------------------------------
# Step 2: Check for Multicollinearity
# -----------------------------------------------------------------------------------------------------------------------------------------
# Install the 'car' package if not already installed
if (!require(car)) install.packages("car")
library(car)
# Calculate Variance Inflation Factor (VIF) for predictors
vif_values <- vif(model_full)
print(vif_values)
# -----------------------------------------------------------------------------------------------------------------------------------------
# Key Findings from Step 2 (Multicollinearity):
# -----------------------------------------------------------------------------------------------------------------------------------------
# 1. Check:
#      - We expect that Acousticness and Energy are explaining the same thing (VIF = 2.2-2.4)
# 2. Next Step:
#      -Refit model without Acosticness to confirm hypothesis
# -----------------------------------------------------------------------------------------------------------------------------------------
# Step 3: Refitting the Model Without Acousticness
# -----------------------------------------------------------------------------------------------------------------------------------------
model_refit <- lm(popularity ~ duration_ms + danceability + energy + instrumentalness + liveness + tempo, data = spotify)
summary(model_refit)
vif(model_refit)
# Residual Analysis
# 1. Normality of Residuals
qqnorm(residuals(model_refit))
qqline(residuals(model_refit), col = "red")
# 2. Homoscedasticity (the errors are consistent no matter is the popularity is high/low)
plot(fitted(model_refit), rstudent(model_refit),
xlab = "Fitted Values",
ylab = "Studentized Residuals",
main = "Residuals vs. Fitted Values")
abline(h = 0, col = "red")
hist(residuals(model_refit),
main = "Histogram of Residuals",
xlab = "Residuals",
breaks = 30,
col = "green")
# -----------------------------------------------------------------------------------------------------------------------------------------
# Spotify Song Popularity Analysis: Linear Regression
# -----------------------------------------------------------------------------------------------------------------------------------------
# Author: Julian Griffin
# Purpose: Investigate the relationship between song popularity and multiple characteristics using linear regression
# Data Set Provided Via: Kelly Ramsay
# -----------------------------------------------------------------------------------------------------------------------------------------
# Set working directory and import the dataset
setwd("/Users/juliangriffin/Desktop/R_Projects_Local/R_Projects")
spotify <- read.csv("spotify_data.csv")
# Check the first few rows of the dataset to ensure it loaded correctly
head(spotify)
# -----------------------------------------------------------------------------------------------------------------------------------------
# Step 1: Fit the Full Multiple Linear Regression Model
# -----------------------------------------------------------------------------------------------------------------------------------------
# Fit the initial multiple linear regression model with all predictors
model_full <- lm(popularity ~ duration_ms + danceability + energy + acousticness + instrumentalness + liveness + tempo, data = spotify)
# Output the model summary to examine the coefficients and fit
summary(model_full)
# -----------------------------------------------------------------------------------------------------------------------------------------
# Key Findings from Step 1 (Full Model):
# -----------------------------------------------------------------------------------------------------------------------------------------
# 1. Model Fit:
#    - The model explains only ~1% of the variability in popularity (R^2 = 0.01139).
#    - The low R^2 indicates that popularity is influenced by factors not captured in the model.
#    - Adjusted R^2 supports this, as it accounts for the number of predictors and is similarly low.
# 2. Influential Factors:
#    - Danceability has a positive impact on popularity, implying that more danceable songs tend to be more popular.
#    - Energy, acousticness, and instrumentalness have negative relationships with popularity, suggesting that songs with lower energy or less acoustic features might be more popular.
# 3. Non-Significant Predictors:
#    - Liveness and duration_ms do not show significant effects on popularity. This suggests these factors might not directly influence how popular a song is in the dataset.
# -----------------------------------------------------------------------------------------------------------------------------------------
# Step 2: Check for Multicollinearity
# -----------------------------------------------------------------------------------------------------------------------------------------
# Check multicollinearity between predictors using Variance Inflation Factor (VIF)
if (!require(car)) install.packages("car")
library(car)
# Calculate and display VIF values for each predictor in the full model
vif_values <- vif(model_full)
print(vif_values)
# -----------------------------------------------------------------------------------------------------------------------------------------
# Key Findings from Step 2 (Multicollinearity):
# -----------------------------------------------------------------------------------------------------------------------------------------
# 1. High VIF for certain predictors:
#    - Acousticness and Energy have VIFs between 2.2-2.4, suggesting some collinearity between these variables.
#    - High VIF indicates that these predictors might be explaining the same variation in popularity, leading to redundancy in the model.
# 2. Next Step:
#    - To address collinearity, we can refit the model without Acousticness and observe the impact on VIF and model performance.
# -----------------------------------------------------------------------------------------------------------------------------------------
# Step 3: Refitting the Model Without Acousticness and Comparing Results
# -----------------------------------------------------------------------------------------------------------------------------------------
# Refit the model excluding Acousticness to assess its impact on multicollinearity and model performance
model_refit <- lm(popularity ~ duration_ms + danceability + energy + instrumentalness + liveness + tempo, data = spotify)
# Output the model summary for the refitted model
summary(model_refit)
# Calculate and display VIF values for the refitted model
vif(model_refit)
# -----------------------------------------------------------------------------------------------------------------------------------------
# Key Findings from Step 3 (Without Acousticness):
# -----------------------------------------------------------------------------------------------------------------------------------------
# 1. Coefficient Changes:
#    - The coefficient for Energy has shifted from -5.6 to -1.9, indicating that removing Acousticness has changed how Energy relates to popularity.
# 2. Multicollinearity Reduction:
#    - Removing Acousticness has lowered the VIF values, confirming that the collinearity between Energy and Acousticness was affecting the model.
#    - This suggests a better isolation of the independent effect of Energy on popularity.
# -----------------------------------------------------------------------------------------------------------------------------------------
# Step 4: Check for Assumption Violations
# -----------------------------------------------------------------------------------------------------------------------------------------
# Residual Analysis
# 1.i) Normality of Residuals
# Check the normality of residuals using a Q-Q plot
qqnorm(residuals(model_refit))
qqline(residuals(model_refit), col = "red")
# 1.ii) Histogram of Residuals
# Plot a histogram to visually assess the distribution of residuals
hist(residuals(model_refit),
main = "Histogram of Residuals",
xlab = "Residuals",
breaks = 30,
col = "green")
# 2. Homoscedasticity (Constant Variance of Errors)
# Plot residuals vs. fitted values to check for homoscedasticity (constant error variance)
plot(fitted(model_refit), rstudent(model_refit),
xlab = "Fitted Values",
ylab = "Studentized Residuals",
main = "Residuals vs. Fitted Values")
abline(h = 0, col = "red")
# -----------------------------------------------------------------------------------------------------------------------------------------
# Key Findings from Step 4 (Check Assumptions):
# -----------------------------------------------------------------------------------------------------------------------------------------
# 1. Q-Q Plot:
#    - The Q-Q plot indicates skewness and heavy tails at the ends, suggesting that the residuals do not follow a normal distribution.
#    - This implies a potential violation of the normality assumption of linear regression.
# 2. Histogram:
#    - The histogram shows a roughly normal distribution, but an unusual amount of negative values suggests the data might need further exploration.
# 3. Homoscedasticity:
#    - The plot of residuals vs. fitted values shows a funnel shape, indicating a violation of homoscedasticity, meaning the error variance is not constant across all levels of popularity.
# -----------------------------------------------------------------------------------------------------------------------------------------
# Step 5: Handling Outliers
# -----------------------------------------------------------------------------------------------------------------------------------------
# Filter dataset to exclude songs with zero popularity to address possible outliers
spotify_filtered <- subset(spotify, popularity > 0)
# Refit the model using the filtered dataset
model_filtered <- lm(popularity ~ duration_ms + danceability + energy +
acousticness + instrumentalness + liveness + tempo,
data = spotify_filtered)
# Display summary and diagnostic plots for the filtered model
summary(model_filtered)
# Check the normality of residuals for the filtered model
qqnorm(residuals(model_filtered))
qqline(residuals(model_filtered), col = "blue")
# Plot residuals vs. fitted values for the filtered model to check homoscedasticity
plot(fitted(model_filtered), rstudent(model_filtered),
xlab = "Fitted Values",
ylab = "Studentized Residuals",
main = "Residuals vs. Fitted Values (Filtered Data)")
abline(h = 0, col = "blue")
# -----------------------------------------------------------------------------------------------------------------------------------------
# Key Findings from Step 5 (Handling Outliers):
# -----------------------------------------------------------------------------------------------------------------------------------------
# 1. Removing Acousticness reduced multicollinearity and improved coefficient stability, particularly for the Energy predictor.
# 2. Filtering out zero-popularity songs improved the normality of the residuals and mitigated some issues with heavy tails.
# 3. Despite these improvements, the model still has low explanatory power, suggesting that factors outside the model (e.g., marketing, artist fame) may play a significant role in determining song popularity.
# -----------------------------------------------------------------------------------------------------------------------------------------
# Conclusion & Recommendations
# -----------------------------------------------------------------------------------------------------------------------------------------
# While the model identifies some key predictors (e.g., Danceability and Energy), it is clear that many external factors not captured in the data are influencing popularity.
# Future work might explore incorporating other variables such as marketing efforts, genre, or artist popularity to improve the model.
# Additionally, testing non-linear relationships or using machine learning models might yield better results for predicting song popularity.
# First, filter dataset to exclude songs with zero popularity to address possible outliers
spotify_filtered <- subset(spotify, popularity > 0)
# Refit the model using the filtered dataset
model_filtered <- lm(popularity ~ duration_ms + danceability + energy + acousticness + instrumentalness + liveness + tempo, data = spotify_filtered)
# Display summary and diagnostic plots for the filtered model
summary(model_filtered)
# Check the normality of residuals for the filtered model using Q-Q plot
qqnorm(residuals(model_filtered))
qqline(residuals(model_filtered), col = "blue")
# Plot residuals vs. fitted values to check for homoscedasticity (constant variance)
plot(fitted(model_filtered), rstudent(model_filtered),
xlab = "Fitted Values",
ylab = "Studentized Residuals",
main = "Residuals vs. Fitted Values (Filtered Data)")
abline(h = 0, col = "blue")
# Next, we indicate which covariates violate the assumptions of the model
# Install and load ggplot2 for further visualization
library(ggplot2)
# Create a new data frame for studentized residuals and fitted values
spotify_filtered$residuals <- rstudent(model_filtered)
spotify_filtered$fitted <- fitted(model_filtered)
# List of covariates to plot against studentized residuals
covariates <- c("duration_ms", "danceability", "energy", "acousticness", "instrumentalness", "liveness", "tempo")
# Plot studentized residuals against each covariate
par(mfrow = c(3, 3))  # Adjust the layout for multiple plots
for (covariate in covariates) {
plot(spotify_filtered[[covariate]], spotify_filtered$residuals,
xlab = covariate,
ylab = "Studentized Residuals",
main = paste("Studentized Residuals vs.", covariate))
abline(h = 0, col = "red")
}
# Quick Analysis: The covariates liveness, instrumentalness, acousticness, and duration_ms show patterns indicating a violation of homoscedasticity,
#  as the residuals display a non-constant variance across levels of these predictors.
# Finally, refit the model excluding problematic covariates (liveness, instrumentalness, acousticness, duration_ms) and non-zero popularity
model_reduced <- lm(popularity ~ danceability + energy + tempo, data = spotify_filtered)
# Display summary of the reduced model
summary(model_reduced)
# Q-Q plot of new residuals
qqnorm(residuals(model_reduced))
qqline(residuals(model_reduced), col = "red")
# Studentized residuals for the reduced model
studentized_residuals_reduced <- rstudent(model_reduced)
fitted_values_reduced <- fitted(model_reduced)
# Studentized residuals vs fitted values for the reduced model
ggplot(data.frame(fitted_values_reduced, studentized_residuals_reduced), aes(x = fitted_values_reduced, y = studentized_residuals_reduced)) +
geom_point() +
labs(x = "Fitted Values", y = "Studentized Residuals") +
geom_hline(yintercept = 0, color = "red") +
theme_minimal()
# First, address the large number of zero values in popularity to eliminate possible outliers.
# Filter dataset to exclude songs with zero popularity
spotify_filtered <- subset(spotify, popularity > 0)
# Refit the model using the filtered dataset
model_filtered <- lm(popularity ~ duration_ms + danceability + energy + acousticness + instrumentalness + liveness + tempo, data = spotify_filtered)
# Display summary and diagnostic plots for the filtered model
summary(model_filtered)
# Next, address violations of assumptions related to individual covariates.
# We will plot each covariate against the residuals to check for violations.
# Install and load ggplot2 if not already installed, for better visualization
if (!require(ggplot2)) install.packages("ggplot2")
library(ggplot2)
# Create a new data frame to store studentized residuals and fitted values
spotify_filtered$residuals <- rstudent(model_filtered)
spotify_filtered$fitted <- fitted(model_filtered)
# List of covariates to examine against studentized residuals
covariates <- c("duration_ms", "danceability", "energy", "acousticness", "instrumentalness", "liveness", "tempo")
# Plot studentized residuals against each covariate to assess homoscedasticity
par(mfrow = c(3, 3))  # Set up the layout for multiple plots
for (covariate in covariates) {
plot(spotify_filtered[[covariate]], spotify_filtered$residuals,
xlab = covariate,
ylab = "Studentized Residuals",
main = paste("Studentized Residuals vs.", covariate))
abline(h = 0, col = "red")  # Add a horizontal line at y=0 for reference
}
# Quick Analysis:
# Covariates such as liveness, instrumentalness, acousticness, and duration_ms show non-constant variance (funnel shapes), indicating violations of homoscedasticity.
# Finally, refit the model excluding problematic covariates (liveness, instrumentalness, acousticness, duration_ms) and using only songs with non-zero popularity
model_reduced <- lm(popularity ~ danceability + energy + tempo, data = spotify_filtered)
# Display summary of the reduced model
summary(model_reduced)
# Plot residuals vs. fitted values for the reduced model to check homoscedasticity
plot(fitted(model_reduced), rstudent(model_reduced),
xlab = "Fitted Values",
ylab = "Studentized Residuals",
main = "Residuals vs. Fitted Values (Reduced Data)")
abline(h = 0, col = "blue")  # Horizontal line at y=0 to indicate zero residuals
# Q-Q plot of residuals for the reduced model
qqnorm(residuals(model_reduced))
qqline(residuals(model_reduced), col = "red")  # Add a reference line for normality
# Histogram of residuals for the reduced model
hist(residuals(model_reduced), breaks = 20, main = "Histogram of Residuals (Reduced Model)",
xlab = "Residuals", col = "skyblue", border = "black")
# Calculate studentized residuals for the reduced model
studentized_residuals_reduced <- rstudent(model_reduced)
fitted_values_reduced <- fitted(model_reduced)
# Plot studentized residuals against fitted values for the reduced model using ggplot2
ggplot(data.frame(fitted_values_reduced, studentized_residuals_reduced), aes(x = fitted_values_reduced, y = studentized_residuals_reduced)) +
geom_point() +
labs(x = "Fitted Values", y = "Studentized Residuals") +
geom_hline(yintercept = 0, color = "red") +  # Add reference line at y=0
theme_minimal()
# Step 6: Handling Outliers and Influence Points
# -----------------------------------------------------------------------------------------------------------------------------------------
# First, we explore the effects of leverage points
# Calculate hat values (leverage values)
hat_values <- hatvalues(model_reduced)
# Identify the observation with the largest hat value
max_hat_value <- which.max(hat_values)
cat("Observation with largest hat value:", max_hat_value, "\n")
# Calculate the proportion of values greater than 2p/n
p <- length(coef(model_reduced))  # number of predictors (including intercept)
n <- nrow(spotify_filtered)  # number of observations
threshold <- 2 * p / n
cat("Proportion of hat values greater than", threshold, ":", mean(hat_values > threshold), "\n")
# Next, we explore the effects of Influence Points
# Calculate Cook's distance
cooks_distance <- cooks.distance(model_reduced)
# Identify the observation with the largest Cook's distance
max_cooks_distance <- which.max(cooks_distance)
cat("Observation with largest Cook's distance:", max_cooks_distance, "\n")
# Calculate the proportion of values greater than 1
cat("Proportion of Cook's distances greater than 1:", mean(cooks_distance > 1), "\n")
# Finally, we visualize the effects of both Leverage and Influence Points
# Plot residuals vs fitted values, highlighting the influential point
plot(fitted(model_reduced), rstudent(model_reduced),
xlab = "Fitted Values", ylab = "Studentized Residuals",
main = "Residuals vs. Fitted Values (with highlighted influence points)")
# Highlight the point with the largest Cook's distance
points(fitted(model_reduced)[max_cooks_distance],
rstudent(model_reduced)[max_cooks_distance],
col = "red", pch = 16)
# Add a reference line at 0
abline(h = 0, col = "blue")
summary(model_reduced)
